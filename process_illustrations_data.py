#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç»˜æœ¬æ’å›¾æ•°æ®å¤„ç†è„šæœ¬
åŠŸèƒ½ï¼šè¯»å–æ—§çš„æè¿°æ–‡æœ¬ï¼Œç”¨AIåˆ†æå¡«å……7ä¸ªä¸»é¢˜å­—æ®µï¼Œå¹¶ç”Ÿæˆå¯¹åº”çš„å‘é‡åµŒå…¥
ä½œè€…ï¼šAI Assistant
"""

import os
import json
import time
import logging
from typing import List, Dict, Optional
from datetime import datetime

# ç¬¬ä¸‰æ–¹åº“å¯¼å…¥
import openai
from supabase import create_client, Client
from openai import OpenAI

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('illustration_processing.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class IllustrationProcessor:
    """ç»˜æœ¬æ’å›¾æ•°æ®å¤„ç†å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–å¤„ç†å™¨ï¼Œè®¾ç½®APIå®¢æˆ·ç«¯"""
        self.setup_clients()
        self.batch_size = 10  # æ¯æ‰¹å¤„ç†çš„è®°å½•æ•°ï¼ˆå‡å°‘æ‰¹æ¬¡å¤§å°æå‡ç¨³å®šæ€§ï¼‰
        
        # å®šä¹‰7ä¸ªä¸»é¢˜å­—æ®µ
        self.theme_fields = [
            'theme_philosophy',
            'action_process', 
            'interpersonal_roles',
            'edu_value',
            'learning_strategy',
            'creative_play',
            'scene_visuals'
        ]
        
        # å¯¹åº”çš„å‘é‡å­—æ®µ
        self.embedding_fields = [f"{field}_embedding" for field in self.theme_fields]
        
    def setup_clients(self):
        """è®¾ç½®Supabaseå’ŒOpenAIå®¢æˆ·ç«¯"""
        # ä¼˜å…ˆä»ç¯å¢ƒå˜é‡è·å–é…ç½®ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä»config.pyè·å–
        supabase_url = os.getenv('SUPABASE_URL')
        supabase_key = os.getenv('SUPABASE_ANON_KEY')  # æˆ–ä½¿ç”¨ SERVICE_ROLE_KEY
        openai_api_key = os.getenv('OPENAI_API_KEY')
        
        # å°è¯•ä»config.pyå¯¼å…¥é…ç½®ï¼ˆä¼˜å…ˆä½¿ç”¨config.pyä¸­çš„é…ç½®ï¼‰
        openai_base_url = None
        try:
            import config
            supabase_url = config.SUPABASE_URL
            supabase_key = config.SUPABASE_ANON_KEY
            openai_api_key = config.OPENAI_API_KEY
            # æ£€æŸ¥æ˜¯å¦æœ‰è‡ªå®šä¹‰çš„OpenAI Base URL
            if hasattr(config, 'OPENAI_BASE_URL'):
                openai_base_url = config.OPENAI_BASE_URL
            logger.info("ä»config.pyæ–‡ä»¶åŠ è½½é…ç½®")
        except ImportError:
            # å¦‚æœconfig.pyä¸å­˜åœ¨ï¼Œä½¿ç”¨ç¯å¢ƒå˜é‡
            logger.info("config.pyä¸å­˜åœ¨ï¼Œä½¿ç”¨ç¯å¢ƒå˜é‡")
            pass
        
        if not all([supabase_url, supabase_key, openai_api_key]):
            raise ValueError("è¯·è®¾ç½®ç¯å¢ƒå˜é‡æˆ–åœ¨config.pyä¸­é…ç½®ï¼šSUPABASE_URL, SUPABASE_ANON_KEY, OPENAI_API_KEY")
        
        # åˆå§‹åŒ–å®¢æˆ·ç«¯
        self.supabase: Client = create_client(supabase_url, supabase_key)
        
        # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯ï¼Œæ”¯æŒè‡ªå®šä¹‰base_url
        if openai_base_url:
            self.openai_client = OpenAI(api_key=openai_api_key, base_url=openai_base_url)
            logger.info(f"ä½¿ç”¨è‡ªå®šä¹‰OpenAI APIåœ°å€: {openai_base_url}")
        else:
            self.openai_client = OpenAI(api_key=openai_api_key)
        
        logger.info("å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
    
    def get_pending_records(self, force_update: bool = False, processed_ids: set = None) -> List[Dict]:
        """è·å–å¾…å¤„ç†çš„è®°å½•"""
        try:
            if force_update:
                # å¼ºåˆ¶æ›´æ–°æ¨¡å¼ï¼šè·å–æ‰€æœ‰æœ‰original_descriptionçš„è®°å½•ï¼Œä½†æ’é™¤æœ¬æ¬¡å·²å¤„ç†çš„
                query = self.supabase.table('illustrations_optimized') \
                    .select('id, filename, original_description') \
                    .not_.is_('original_description', 'null')
                
                # å¦‚æœæœ‰å·²å¤„ç†çš„IDåˆ—è¡¨ï¼Œæ’é™¤å®ƒä»¬
                if processed_ids:
                    query = query.not_.in_('id', list(processed_ids))
                
                response = query.limit(self.batch_size).execute()
                
                if not processed_ids:  # åªåœ¨ç¬¬ä¸€æ¬¡æ˜¾ç¤º
                    logger.info("å¼ºåˆ¶æ›´æ–°æ¨¡å¼ï¼šå°†é‡æ–°å¤„ç†æ‰€æœ‰è®°å½•")
            else:
                # æ­£å¸¸æ¨¡å¼ï¼šåªå¤„ç†theme_philosophyä¸ºNULLçš„è®°å½•
                response = self.supabase.table('illustrations_optimized') \
                    .select('id, filename, original_description') \
                    .is_('theme_philosophy', 'null') \
                    .limit(self.batch_size) \
                    .execute()
            
            return response.data
        except Exception as e:
            logger.error(f"è·å–å¾…å¤„ç†è®°å½•å¤±è´¥: {e}")
            return []
    
    def analyze_with_gpt4(self, description: str) -> Optional[Dict]:
        """ä½¿ç”¨GPT-4oåˆ†ææè¿°æ–‡æœ¬ï¼Œæå–7ä¸ªä¸»é¢˜å­—æ®µ"""
        
        prompt = f"""ç›®æ ‡ï¼šè¯·ä½ æ‰®æ¼”ä¸€ä½èµ„æ·±çš„æ–‡æœ¬åˆ†æå’Œä¿¡æ¯æå–ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ·±å…¥åˆ†ææˆ‘æä¾›çš„è¿™æ®µå…³äºç»˜æœ¬æ’å›¾çš„è¯¦ç»†æè¿°æ–‡å­—ï¼Œå¹¶ä»ä¸­æå–å…³é”®ä¿¡æ¯ï¼Œä¸ºä¸€ä¸ªJSONå¯¹è±¡ä¸­çš„7ä¸ªæ ¸å¿ƒå­—æ®µå¡«å……å†…å®¹ã€‚

è¾“å…¥ï¼šä¸€æ®µå…³äºç»˜æœ¬æ’å›¾çš„è¯¦ç»†æè¿°æ–‡å­—ã€‚

å­—æ®µå¡«å†™æŒ‡å—ï¼š
- theme_philosophy (æ ¸å¿ƒç†å¿µä¸äººç”Ÿä¸»é¢˜)ï¼šåˆ†æç”»é¢ä¼ é€’çš„é™æ€ä»·å€¼è§‚ã€äººç”Ÿæ€åº¦ã€ä¸–ç•Œè§‚ç­‰ã€‚ä¾‹å¦‚ï¼šå¯¹ç¾çš„çœ‹æ³•ã€ç”Ÿæ´»çš„æ„ä¹‰ã€å¹¸ç¦çš„å®šä¹‰ã€‚
- action_process (è¡ŒåŠ¨è¿‡ç¨‹ä¸æˆé•¿)ï¼šåˆ†æç”»é¢ä¸­è§’è‰²çš„åŠ¨æ€è¡Œä¸ºã€‚æè¿°ä»–ä»¬æ­£åœ¨åšä»€ä¹ˆã€ç»å†ä»€ä¹ˆæŒ‘æˆ˜ã€å¦‚ä½•å…‹æœï¼Œä»¥åŠè¿™ä¸ªè¿‡ç¨‹å¸¦æ¥çš„æˆé•¿ã€‚ä¾‹å¦‚ï¼šæ¢ç´¢ã€åšæŒã€çŠ¯é”™ã€åŠªåŠ›ã€‚
- interpersonal_roles (äººé™…è§’è‰²ä¸æƒ…æ„Ÿè¿æ¥)ï¼šåˆ†æç”»é¢ä¸­äººç‰©ä¹‹é—´çš„å…³ç³»å’Œæƒ…æ„Ÿã€‚æ˜¯äº²å­ã€å¸ˆç”Ÿè¿˜æ˜¯æœ‹å‹ï¼Ÿä»–ä»¬ä¹‹é—´çš„äº’åŠ¨æ˜¯å…³çˆ±ã€æ”¯æŒã€å¼•å¯¼è¿˜æ˜¯é™ªä¼´ï¼Ÿ
- edu_value (é˜…è¯»å¸¦æ¥çš„ä»·å€¼)ï¼šæ€è€ƒè¿™æœ¬ä¹¦èƒ½å¸¦ç»™å­©å­çš„å®è§‚æ•™è‚²æ„ä¹‰ã€‚å®ƒå¦‚ä½•å¡‘é€ å“æ ¼ã€æ‹“å®½è§†é‡ã€åŸ¹å…»å®¡ç¾ï¼Ÿ
- learning_strategy (é˜…è¯»ä¸­çš„å­¦ä¹ æ–¹æ³•)ï¼šåˆ†æç”»é¢ä¸­æ˜¯å¦å±•ç°æˆ–æš—ç¤ºäº†å…·ä½“çš„å­¦ä¹ æ–¹æ³•ã€‚ä¾‹å¦‚ï¼šè§‚å¯Ÿã€æé—®ã€å¯¹æ¯”ã€è¾“å‡ºã€è§’è‰²æ‰®æ¼”ç­‰ã€‚
- creative_play (åˆ›æ„è¡¨ç°ä¸æƒ³è±¡åŠ›)ï¼šåˆ†æç”»é¢ä¸­çš„æ¸¸æˆã€å¹»æƒ³ã€è§’è‰²æ‰®æ¼”ç­‰å…ƒç´ ã€‚å®ƒå¦‚ä½•æ¿€å‘å­©å­çš„åˆ›é€ åŠ›å’Œæƒ³è±¡åŠ›ï¼Ÿ
- scene_visuals (åœºæ™¯æ°›å›´ä¸ç”»é¢å…ƒç´ )ï¼šæè¿°ç”»é¢çš„ç‰©ç†ä¿¡æ¯ã€‚åŒ…æ‹¬åœºæ™¯ï¼ˆå®¤å†…/å¤–ï¼‰ã€å­£èŠ‚ã€å¤©æ°”ã€å…‰çº¿ã€è‰²å½©è¿ç”¨ã€è‰ºæœ¯é£æ ¼ä»¥åŠè¥é€ å‡ºçš„æ•´ä½“æ°›å›´ï¼ˆæ¸©é¦¨ã€å®é™ã€çƒ­é—¹ã€ç¥ç§˜ç­‰ï¼‰ã€‚

è¾“å‡ºæ ¼å¼è¦æ±‚ï¼šä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼Œä¸è¦æ·»åŠ ä»»ä½•é¢å¤–çš„è§£é‡Šæˆ–è¯´æ˜æ–‡å­—ã€‚

{{
  "theme_philosophy": "æ ¹æ®ä¸Šè¿°æŒ‡å—åˆ†æå¾—å‡ºçš„æ ¸å¿ƒç†å¿µä¸äººç”Ÿä¸»é¢˜",
  "action_process": "æ ¹æ®ä¸Šè¿°æŒ‡å—åˆ†æå¾—å‡ºçš„è¡ŒåŠ¨è¿‡ç¨‹ä¸æˆé•¿",
  "interpersonal_roles": "æ ¹æ®ä¸Šè¿°æŒ‡å—åˆ†æå¾—å‡ºçš„äººé™…è§’è‰²ä¸æƒ…æ„Ÿè¿æ¥",
  "edu_value": "æ ¹æ®ä¸Šè¿°æŒ‡å—åˆ†æå¾—å‡ºçš„é˜…è¯»å¸¦æ¥çš„ä»·å€¼",
  "learning_strategy": "æ ¹æ®ä¸Šè¿°æŒ‡å—åˆ†æå¾—å‡ºçš„é˜…è¯»ä¸­çš„å­¦ä¹ æ–¹æ³•",
  "creative_play": "æ ¹æ®ä¸Šè¿°æŒ‡å—åˆ†æå¾—å‡ºçš„åˆ›æ„è¡¨ç°ä¸æƒ³è±¡åŠ›",
  "scene_visuals": "æ ¹æ®ä¸Šè¿°æŒ‡å—åˆ†æå¾—å‡ºçš„åœºæ™¯æ°›å›´ä¸ç”»é¢å…ƒç´ "
}}

å¾…åˆ†æçš„æè¿°æ–‡å­—ï¼š
{description}"""

        try:
            response = self.openai_client.chat.completions.create(
                model="gpt-4o-2024-11-20",
                messages=[
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ–‡æœ¬åˆ†æä¸“å®¶ï¼Œæ“…é•¿ä»ç»˜æœ¬æ’å›¾æè¿°ä¸­æå–æ·±å±‚å«ä¹‰ã€‚è¯·ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¿”å›ç»“æœã€‚"
                    },
                    {
                        "role": "user", 
                        "content": prompt
                    }
                ],
                temperature=0.3,
                max_tokens=1500
            )
            
            logger.info(f"ä½¿ç”¨æ¨¡å‹: {response.model}")
            
            # è§£æJSONå“åº”
            content = response.choices[0].message.content.strip()
            
            # ç§»é™¤å¯èƒ½çš„markdownä»£ç å—æ ‡è®°
            if content.startswith('```json'):
                content = content[7:]
            if content.endswith('```'):
                content = content[:-3]
            
            return json.loads(content)
            
        except json.JSONDecodeError as e:
            logger.error(f"JSONè§£æå¤±è´¥: {e}, åŸå§‹å†…å®¹: {content}")
            return None
        except Exception as e:
            logger.error(f"GPT-4åˆ†æå¤±è´¥: {e}")
            return None
    
    def generate_embeddings(self, texts: List[str]) -> Optional[List[List[float]]]:
        """ä¸ºæ–‡æœ¬åˆ—è¡¨ç”Ÿæˆå‘é‡åµŒå…¥"""
        try:
            # è¿‡æ»¤ç©ºæ–‡æœ¬
            valid_texts = [text for text in texts if text and text.strip()]
            if not valid_texts:
                return None
                
            response = self.openai_client.embeddings.create(
                model="text-embedding-3-small",
                input=valid_texts,
                encoding_format="float"
            )
            
            embeddings = [embedding.embedding for embedding in response.data]
            # æ·»åŠ å‘é‡ç»´åº¦è°ƒè¯•ä¿¡æ¯
            if embeddings:
                logger.info(f"ç”Ÿæˆå‘é‡ç»´åº¦: {len(embeddings[0])}")
            return embeddings
            
        except Exception as e:
            logger.error(f"å‘é‡ç”Ÿæˆå¤±è´¥: {e}")
            return None
    
    def update_record(self, record_id: str, theme_data: Dict, embeddings: List[List[float]]) -> bool:
        """æ›´æ–°æ•°æ®åº“è®°å½•"""
        try:
            # å‡†å¤‡æ›´æ–°æ•°æ®
            update_data = {}
            
            # æ·»åŠ æ–‡æœ¬å­—æ®µ
            for field in self.theme_fields:
                if field in theme_data:
                    update_data[field] = theme_data[field]
            
            # æ·»åŠ å‘é‡å­—æ®µ
            for i, embedding_field in enumerate(self.embedding_fields):
                if i < len(embeddings):
                    update_data[embedding_field] = embeddings[i]
            
            # æ›´æ–°æ—¶é—´æˆ³
            update_data['updated_at'] = datetime.now().isoformat()
            
            # æ‰§è¡Œæ›´æ–°
            response = self.supabase.table('illustrations_optimized') \
                .update(update_data) \
                .eq('id', record_id) \
                .execute()
            
            return len(response.data) > 0
            
        except Exception as e:
            logger.error(f"æ›´æ–°è®°å½•å¤±è´¥ (ID: {record_id}): {e}")
            return False
    
    def process_single_record(self, record: Dict) -> bool:
        """å¤„ç†å•æ¡è®°å½•"""
        record_id = record['id']
        filename = record['filename']
        description = record['original_description']
        
        logger.info(f"æ­£åœ¨å¤„ç†è®°å½•ID: {record_id}, æ–‡ä»¶å: {filename}")
        
        # æ£€æŸ¥æè¿°æ˜¯å¦å­˜åœ¨
        if not description or not description.strip():
            logger.warning(f"è®°å½• {record_id} çš„åŸå§‹æè¿°ä¸ºç©ºï¼Œè·³è¿‡å¤„ç†")
            return False
        
        # 1. ä½¿ç”¨GPT-4åˆ†ææ–‡æœ¬
        logger.info(f"  â†’ æ­£åœ¨è°ƒç”¨GPT-4åˆ†ææ–‡æœ¬...")
        theme_data = self.analyze_with_gpt4(description)
        if not theme_data:
            logger.error(f"  â†’ GPT-4åˆ†æå¤±è´¥ï¼Œè·³è¿‡è®°å½• {record_id}")
            return False
        
        # 2. ç”Ÿæˆå‘é‡åµŒå…¥
        logger.info(f"  â†’ æ­£åœ¨ç”Ÿæˆå‘é‡åµŒå…¥...")
        texts_for_embedding = [theme_data.get(field, '') for field in self.theme_fields]
        embeddings = self.generate_embeddings(texts_for_embedding)
        if not embeddings:
            logger.error(f"  â†’ å‘é‡ç”Ÿæˆå¤±è´¥ï¼Œè·³è¿‡è®°å½• {record_id}")
            return False
        
        # 3. æ›´æ–°æ•°æ®åº“
        logger.info(f"  â†’ æ­£åœ¨æ›´æ–°æ•°æ®åº“...")
        success = self.update_record(record_id, theme_data, embeddings)
        
        if success:
            logger.info(f"  âœ“ è®°å½• {record_id} å¤„ç†å®Œæˆ")
            return True
        else:
            logger.error(f"  âœ— è®°å½• {record_id} æ›´æ–°å¤±è´¥")
            return False
    
    def get_total_records_count(self, force_update: bool = False) -> int:
        """è·å–æ€»è®°å½•æ•°"""
        try:
            if force_update:
                response = self.supabase.table('illustrations_optimized') \
                    .select('id', count='exact') \
                    .not_.is_('original_description', 'null') \
                    .execute()
            else:
                response = self.supabase.table('illustrations_optimized') \
                    .select('id', count='exact') \
                    .is_('theme_philosophy', 'null') \
                    .execute()
            return response.count if response.count else 0
        except Exception as e:
            logger.error(f"è·å–æ€»è®°å½•æ•°å¤±è´¥: {e}")
            return 0
    
    def run(self, force_update: bool = False):
        """è¿è¡Œä¸»å¤„ç†æµç¨‹"""
        if force_update:
            logger.info("å¼€å§‹å¼ºåˆ¶æ›´æ–°ç»˜æœ¬æ’å›¾æ•°æ®ï¼ˆå°†é‡æ–°å¤„ç†æ‰€æœ‰è®°å½•ï¼‰...")
        else:
            logger.info("å¼€å§‹å¤„ç†ç»˜æœ¬æ’å›¾æ•°æ®...")
        
        # è·å–æ€»è®°å½•æ•°
        total_records = self.get_total_records_count(force_update)
        logger.info(f"æ€»å…±éœ€è¦å¤„ç† {total_records} æ¡è®°å½•")
        
        total_processed = 0
        total_success = 0
        start_time = time.time()
        processed_ids = set()  # è·Ÿè¸ªæœ¬æ¬¡è¿è¡Œå·²å¤„ç†çš„è®°å½•ID
        
        while True:
            # è·å–å¾…å¤„ç†è®°å½•
            records = self.get_pending_records(force_update=force_update, processed_ids=processed_ids)
            
            if not records:
                logger.info("æ²¡æœ‰æ›´å¤šå¾…å¤„ç†çš„è®°å½•ï¼Œå¤„ç†å®Œæˆï¼")
                break
            
            logger.info(f"è·å–åˆ° {len(records)} æ¡å¾…å¤„ç†è®°å½•")
            
            # å¤„ç†å½“å‰æ‰¹æ¬¡
            batch_success = 0
            for record in records:
                try:
                    record_id = record['id']
                    
                    if self.process_single_record(record):
                        batch_success += 1
                        total_success += 1
                    
                    total_processed += 1
                    processed_ids.add(record_id)  # è®°å½•å·²å¤„ç†çš„ID
                    
                    # æ·»åŠ å»¶è¿Ÿä»¥é¿å…APIé™åˆ¶ï¼ˆè¿›ä¸€æ­¥å‡å°‘å»¶è¿Ÿï¼‰
                    time.sleep(0.2)
                    
                except Exception as e:
                    logger.error(f"å¤„ç†è®°å½•æ—¶å‘ç”Ÿæœªé¢„æœŸé”™è¯¯: {e}")
                    continue
            
            logger.info(f"å½“å‰æ‰¹æ¬¡å®Œæˆ: {batch_success}/{len(records)} æˆåŠŸ")
            
            # è®¡ç®—è¿›åº¦å’Œé¢„ä¼°æ—¶é—´
            progress_percentage = (total_processed / total_records * 100) if total_records > 0 else 0
            elapsed_time = time.time() - start_time
            if total_processed > 0:
                avg_time_per_record = elapsed_time / total_processed
                remaining_records = total_records - total_processed
                estimated_remaining_time = remaining_records * avg_time_per_record
                
                logger.info(f"ğŸ“Š æ€»ä½“è¿›åº¦: {total_success}/{total_processed}/{total_records} "
                          f"({progress_percentage:.1f}%) æˆåŠŸç‡: {total_success/total_processed*100:.1f}%")
                logger.info(f"â±ï¸  å·²ç”¨æ—¶: {elapsed_time/60:.1f}åˆ†é’Ÿ, é¢„è®¡å‰©ä½™: {estimated_remaining_time/60:.1f}åˆ†é’Ÿ")
            else:
                logger.info(f"ğŸ“Š æ€»ä½“è¿›åº¦: {total_success}/{total_processed}/{total_records}")
            
            # æ‰¹æ¬¡é—´ä¼‘æ¯ï¼ˆå‡å°‘å»¶è¿Ÿï¼‰
            time.sleep(1)
        
        elapsed_time = time.time() - start_time
        logger.info(f"ğŸ‰ æ‰€æœ‰æ•°æ®å¤„ç†å®Œæˆï¼æ€»è®¡å¤„ç†: {total_processed} æ¡ï¼ŒæˆåŠŸ: {total_success} æ¡")
        logger.info(f"â±ï¸  æ€»ç”¨æ—¶: {elapsed_time/60:.1f}åˆ†é’Ÿï¼Œå¹³å‡æ¯æ¡: {elapsed_time/total_processed:.1f}ç§’")

def main():
    """ä¸»å‡½æ•°"""
    try:
        # æ£€æŸ¥å‘½ä»¤è¡Œå‚æ•°
        import sys
        force_update = '--force-update' in sys.argv or '--update' in sys.argv
        
        # åˆ›å»ºå¤„ç†å™¨å¹¶è¿è¡Œ
        processor = IllustrationProcessor()
        processor.run(force_update=force_update)
        
    except KeyboardInterrupt:
        logger.info("ç”¨æˆ·ä¸­æ–­å¤„ç†æµç¨‹")
    except Exception as e:
        logger.error(f"ç¨‹åºè¿è¡Œå‡ºé”™: {e}")

if __name__ == "__main__":
    main()