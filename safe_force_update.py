#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å®‰å…¨çš„å¼ºåˆ¶æ›´æ–°è„šæœ¬ - é¿å…é‡å¤å¤„ç†é—®é¢˜
é€šè¿‡ä¸´æ—¶æ ‡è®°å­—æ®µæ¥ç¡®ä¿æ¯æ¡è®°å½•åªå¤„ç†ä¸€æ¬¡
"""

import os
import json
import time
import logging
from typing import List, Dict, Optional
from datetime import datetime
import uuid

# ç¬¬ä¸‰æ–¹åº“å¯¼å…¥
import openai
from supabase import create_client, Client
from openai import OpenAI

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('safe_update.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class SafeForceUpdater:
    """å®‰å…¨çš„å¼ºåˆ¶æ›´æ–°å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–"""
        self.setup_clients()
        self.batch_size = 10
        self.session_id = str(uuid.uuid4())[:8]  # æœ¬æ¬¡è¿è¡Œçš„å”¯ä¸€æ ‡è¯†
        
        # å®šä¹‰7ä¸ªä¸»é¢˜å­—æ®µ
        self.theme_fields = [
            'theme_philosophy',
            'action_process', 
            'interpersonal_roles',
            'edu_value',
            'learning_strategy',
            'creative_play',
            'scene_visuals'
        ]
        
        # å¯¹åº”çš„å‘é‡å­—æ®µ
        self.embedding_fields = [f"{field}_embedding" for field in self.theme_fields]
        
    def setup_clients(self):
        """è®¾ç½®Supabaseå’ŒOpenAIå®¢æˆ·ç«¯"""
        try:
            import config
            supabase_url = config.SUPABASE_URL
            supabase_key = config.SUPABASE_ANON_KEY
            openai_api_key = config.OPENAI_API_KEY
            
            # åˆå§‹åŒ–å®¢æˆ·ç«¯
            self.supabase: Client = create_client(supabase_url, supabase_key)
            
            # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯ï¼Œæ”¯æŒè‡ªå®šä¹‰base_url
            if hasattr(config, 'OPENAI_BASE_URL'):
                self.openai_client = OpenAI(api_key=openai_api_key, base_url=config.OPENAI_BASE_URL)
                logger.info(f"ä½¿ç”¨è‡ªå®šä¹‰OpenAI APIåœ°å€: {config.OPENAI_BASE_URL}")
            else:
                self.openai_client = OpenAI(api_key=openai_api_key)
            
            logger.info("å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.error(f"å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def mark_processing_start(self):
        """æ ‡è®°å¼€å§‹å¤„ç† - æ·»åŠ ä¸´æ—¶å­—æ®µ"""
        logger.info("å‡†å¤‡å¼€å§‹å®‰å…¨å¼ºåˆ¶æ›´æ–°...")
        
        try:
            # ç»Ÿè®¡éœ€è¦å¤„ç†çš„è®°å½•
            response = self.supabase.table('illustrations_optimized') \
                .select('id', count='exact') \
                .not_.is_('original_description', 'null') \
                .execute()
            
            total_count = response.count or 0
            logger.info(f"æ€»å…±éœ€è¦å¤„ç† {total_count} æ¡è®°å½•")
            
            return total_count
            
        except Exception as e:
            logger.error(f"æ ‡è®°å¤„ç†å¼€å§‹å¤±è´¥: {e}")
            return 0
    
    def get_next_batch(self) -> List[Dict]:
        """è·å–ä¸‹ä¸€æ‰¹å¾…å¤„ç†è®°å½•"""
        try:
            # è·å–è¿˜æ²¡æœ‰å¤„ç†æ ‡è®°çš„è®°å½•
            response = self.supabase.table('illustrations_optimized') \
                .select('id, filename, original_description') \
                .not_.is_('original_description', 'null') \
                .is_('processing_session', 'null') \
                .limit(self.batch_size) \
                .execute()
            
            records = response.data
            
            if records:
                # æ ‡è®°è¿™æ‰¹è®°å½•æ­£åœ¨å¤„ç†
                record_ids = [r['id'] for r in records]
                self.supabase.table('illustrations_optimized') \
                    .update({'processing_session': self.session_id}) \
                    .in_('id', record_ids) \
                    .execute()
                
                logger.info(f"è·å–å¹¶æ ‡è®°äº† {len(records)} æ¡è®°å½•")
            
            return records
            
        except Exception as e:
            logger.error(f"è·å–è®°å½•å¤±è´¥: {e}")
            return []
    
    def analyze_with_gpt4(self, description: str) -> Optional[Dict]:
        """ä½¿ç”¨GPT-4oåˆ†ææè¿°æ–‡æœ¬ï¼Œæå–7ä¸ªä¸»é¢˜å­—æ®µ"""
        
        prompt = f"""ç›®æ ‡ï¼šè¯·ä½ æ‰®æ¼”ä¸€ä½èµ„æ·±çš„æ–‡æœ¬åˆ†æå’Œä¿¡æ¯æå–ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ·±å…¥åˆ†ææˆ‘æä¾›çš„è¿™æ®µå…³äºç»˜æœ¬æ’å›¾çš„è¯¦ç»†æè¿°æ–‡å­—ï¼Œå¹¶ä»ä¸­æå–å…³é”®ä¿¡æ¯ï¼Œä¸ºä¸€ä¸ªJSONå¯¹è±¡ä¸­çš„7ä¸ªæ ¸å¿ƒå­—æ®µå¡«å……å†…å®¹ã€‚

è¾“å…¥ï¼šä¸€æ®µå…³äºç»˜æœ¬æ’å›¾çš„è¯¦ç»†æè¿°æ–‡å­—ã€‚

å­—æ®µå¡«å†™æŒ‡å—ï¼š
- theme_philosophy (æ ¸å¿ƒå“²ç†ä¸äººç”Ÿä¸»é¢˜)ï¼šåˆ†æç”»é¢ä¼ é€’çš„é™æ€ä»·å€¼è§‚ã€äººç”Ÿæ€åº¦ã€ä¸–ç•Œè§‚ç­‰ã€‚ä¾‹å¦‚ï¼šå¯¹ç¾çš„çœ‹æ³•ã€ç”Ÿæ´»çš„æ„ä¹‰ã€å¹¸ç¦çš„å®šä¹‰ã€‚
- action_process (è¡ŒåŠ¨è¿‡ç¨‹ä¸æˆé•¿)ï¼šåˆ†æç”»é¢ä¸­è§’è‰²çš„åŠ¨æ€è¡Œä¸ºã€‚æè¿°ä»–ä»¬æ­£åœ¨åšä»€ä¹ˆã€ç»å†ä»€ä¹ˆæŒ‘æˆ˜ã€å¦‚ä½•å…‹æœï¼Œä»¥åŠè¿™ä¸ªè¿‡ç¨‹å¸¦æ¥çš„æˆé•¿ã€‚ä¾‹å¦‚ï¼šæ¢ç´¢ã€åšæŒã€çŠ¯é”™ã€åŠªåŠ›ã€‚
- interpersonal_roles (äººé™…è§’è‰²ä¸æƒ…æ„Ÿè¿æ¥)ï¼šåˆ†æç”»é¢ä¸­äººç‰©ä¹‹é—´çš„å…³ç³»å’Œæƒ…æ„Ÿã€‚æ˜¯äº²å­ã€å¸ˆç”Ÿè¿˜æ˜¯æœ‹å‹ï¼Ÿä»–ä»¬ä¹‹é—´çš„äº’åŠ¨æ˜¯å…³çˆ±ã€æ”¯æŒã€å¼•å¯¼è¿˜æ˜¯é™ªä¼´ï¼Ÿ
- edu_value (é˜…è¯»æ•™è‚²ä»·å€¼)ï¼šå¦‚æœæ’å›¾æ¥è‡ªä¸€æœ¬ä¹¦ï¼Œæ€è€ƒè¿™æœ¬ä¹¦èƒ½å¸¦ç»™å­©å­çš„å®è§‚æ•™è‚²æ„ä¹‰ã€‚å®ƒå¦‚ä½•å¡‘é€ å“æ ¼ã€æ‹“å®½è§†é‡ã€åŸ¹å…»å®¡ç¾ï¼Ÿ
- learning_strategy (é˜…è¯»å­¦ä¹ ç­–ç•¥)ï¼šåˆ†æç”»é¢ä¸­æ˜¯å¦å±•ç°æˆ–æš—ç¤ºäº†å…·ä½“çš„å­¦ä¹ æ–¹æ³•ã€‚ä¾‹å¦‚ï¼šè§‚å¯Ÿã€æé—®ã€å¯¹æ¯”ã€è¾“å‡ºã€è§’è‰²æ‰®æ¼”ç­‰ã€‚
- creative_play (åˆ›æ„ç©æ³•ä¸æƒ³è±¡åŠ›)ï¼šåˆ†æç”»é¢ä¸­çš„æ¸¸æˆã€å¹»æƒ³ã€è§’è‰²æ‰®æ¼”ç­‰å…ƒç´ ã€‚å®ƒå¦‚ä½•æ¿€å‘å­©å­çš„åˆ›é€ åŠ›å’Œæƒ³è±¡åŠ›ï¼Ÿ
- scene_visuals (åœºæ™¯æ°›å›´ä¸è§†è§‰å…ƒç´ )ï¼šæè¿°ç”»é¢çš„ç‰©ç†ä¿¡æ¯ã€‚åŒ…æ‹¬åœºæ™¯ï¼ˆå®¤å†…/å¤–ï¼‰ã€å­£èŠ‚ã€å¤©æ°”ã€å…‰çº¿ã€è‰²å½©è¿ç”¨ã€è‰ºæœ¯é£æ ¼ä»¥åŠè¥é€ å‡ºçš„æ•´ä½“æ°›å›´ï¼ˆæ¸©é¦¨ã€å®é™ã€çƒ­é—¹ã€ç¥ç§˜ç­‰ï¼‰ã€‚

è¾“å‡ºæ ¼å¼è¦æ±‚ï¼šä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼Œä¸è¦æ·»åŠ ä»»ä½•é¢å¤–çš„è§£é‡Šæˆ–è¯´æ˜æ–‡å­—ã€‚

{{
  "theme_philosophy": "æ ¹æ®ä¸Šè¿°æŒ‡å—åˆ†æå¾—å‡ºçš„æ ¸å¿ƒå“²ç†ä¸äººç”Ÿä¸»é¢˜",
  "action_process": "æ ¹æ®ä¸Šè¿°æŒ‡å—åˆ†æå¾—å‡ºçš„è¡ŒåŠ¨è¿‡ç¨‹ä¸æˆé•¿",
  "interpersonal_roles": "æ ¹æ®ä¸Šè¿°æŒ‡å—åˆ†æå¾—å‡ºçš„äººé™…è§’è‰²ä¸æƒ…æ„Ÿè¿æ¥",
  "edu_value": "æ ¹æ®ä¸Šè¿°æŒ‡å—åˆ†æå¾—å‡ºçš„é˜…è¯»æ•™è‚²ä»·å€¼",
  "learning_strategy": "æ ¹æ®ä¸Šè¿°æŒ‡å—åˆ†æå¾—å‡ºçš„é˜…è¯»å­¦ä¹ ç­–ç•¥",
  "creative_play": "æ ¹æ®ä¸Šè¿°æŒ‡å—åˆ†æå¾—å‡ºçš„åˆ›æ„ç©æ³•ä¸æƒ³è±¡åŠ›",
  "scene_visuals": "æ ¹æ®ä¸Šè¿°æŒ‡å—åˆ†æå¾—å‡ºçš„åœºæ™¯æ°›å›´ä¸è§†è§‰å…ƒç´ "
}}

å¾…åˆ†æçš„æè¿°æ–‡å­—ï¼š
{description}"""

        try:
            response = self.openai_client.chat.completions.create(
                model="gpt-4o-2024-11-20",
                messages=[
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ–‡æœ¬åˆ†æä¸“å®¶ï¼Œæ“…é•¿ä»ç»˜æœ¬æ’å›¾æè¿°ä¸­æå–æ·±å±‚å«ä¹‰ã€‚è¯·ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¿”å›ç»“æœã€‚"
                    },
                    {
                        "role": "user", 
                        "content": prompt
                    }
                ],
                temperature=0.3,
                max_tokens=1500
            )
            
            # è§£æJSONå“åº”
            content = response.choices[0].message.content.strip()
            
            # ç§»é™¤å¯èƒ½çš„markdownä»£ç å—æ ‡è®°
            if content.startswith('```json'):
                content = content[7:]
            if content.endswith('```'):
                content = content[:-3]
            
            return json.loads(content)
            
        except json.JSONDecodeError as e:
            logger.error(f"JSONè§£æå¤±è´¥: {e}, åŸå§‹å†…å®¹: {content}")
            return None
        except Exception as e:
            logger.error(f"GPT-4åˆ†æå¤±è´¥: {e}")
            return None
    
    def generate_embeddings(self, texts: List[str]) -> Optional[List[List[float]]]:
        """ä¸ºæ–‡æœ¬åˆ—è¡¨ç”Ÿæˆå‘é‡åµŒå…¥"""
        try:
            # è¿‡æ»¤ç©ºæ–‡æœ¬
            valid_texts = [text for text in texts if text and text.strip()]
            if not valid_texts:
                return None
                
            response = self.openai_client.embeddings.create(
                model="text-embedding-3-small",
                input=valid_texts,
                encoding_format="float"
            )
            
            embeddings = [embedding.embedding for embedding in response.data]
            return embeddings
            
        except Exception as e:
            logger.error(f"å‘é‡ç”Ÿæˆå¤±è´¥: {e}")
            return None
    
    def update_record(self, record_id: str, theme_data: Dict, embeddings: List[List[float]]) -> bool:
        """æ›´æ–°æ•°æ®åº“è®°å½•å¹¶æ¸…é™¤å¤„ç†æ ‡è®°"""
        try:
            # å‡†å¤‡æ›´æ–°æ•°æ®
            update_data = {}
            
            # æ·»åŠ æ–‡æœ¬å­—æ®µ
            for field in self.theme_fields:
                if field in theme_data:
                    update_data[field] = theme_data[field]
            
            # æ·»åŠ å‘é‡å­—æ®µ
            for i, embedding_field in enumerate(self.embedding_fields):
                if i < len(embeddings):
                    update_data[embedding_field] = embeddings[i]
            
            # æ›´æ–°æ—¶é—´æˆ³å’Œæ¸…é™¤å¤„ç†æ ‡è®°
            update_data['updated_at'] = datetime.now().isoformat()
            update_data['processing_session'] = None  # æ¸…é™¤å¤„ç†æ ‡è®°
            
            # æ‰§è¡Œæ›´æ–°
            response = self.supabase.table('illustrations_optimized') \
                .update(update_data) \
                .eq('id', record_id) \
                .execute()
            
            return len(response.data) > 0
            
        except Exception as e:
            logger.error(f"æ›´æ–°è®°å½•å¤±è´¥ (ID: {record_id}): {e}")
            return False
    
    def process_single_record(self, record: Dict) -> bool:
        """å¤„ç†å•æ¡è®°å½•"""
        record_id = record['id']
        filename = record['filename']
        description = record['original_description']
        
        logger.info(f"æ­£åœ¨å¤„ç†è®°å½•ID: {record_id}, æ–‡ä»¶å: {filename}")
        
        # æ£€æŸ¥æè¿°æ˜¯å¦å­˜åœ¨
        if not description or not description.strip():
            logger.warning(f"è®°å½• {record_id} çš„åŸå§‹æè¿°ä¸ºç©ºï¼Œè·³è¿‡å¤„ç†")
            return False
        
        # 1. ä½¿ç”¨GPT-4åˆ†ææ–‡æœ¬
        logger.info(f"  â†’ æ­£åœ¨è°ƒç”¨GPT-4oåˆ†ææ–‡æœ¬...")
        theme_data = self.analyze_with_gpt4(description)
        if not theme_data:
            logger.error(f"  â†’ GPT-4åˆ†æå¤±è´¥ï¼Œè·³è¿‡è®°å½• {record_id}")
            return False
        
        # 2. ç”Ÿæˆå‘é‡åµŒå…¥
        logger.info(f"  â†’ æ­£åœ¨ç”Ÿæˆå‘é‡åµŒå…¥...")
        texts_for_embedding = [theme_data.get(field, '') for field in self.theme_fields]
        embeddings = self.generate_embeddings(texts_for_embedding)
        if not embeddings:
            logger.error(f"  â†’ å‘é‡ç”Ÿæˆå¤±è´¥ï¼Œè·³è¿‡è®°å½• {record_id}")
            return False
        
        # 3. æ›´æ–°æ•°æ®åº“
        logger.info(f"  â†’ æ­£åœ¨æ›´æ–°æ•°æ®åº“...")
        success = self.update_record(record_id, theme_data, embeddings)
        
        if success:
            logger.info(f"  âœ“ è®°å½• {record_id} å¤„ç†å®Œæˆ")
            return True
        else:
            logger.error(f"  âœ— è®°å½• {record_id} æ›´æ–°å¤±è´¥")
            return False
    
    def cleanup_processing_marks(self):
        """æ¸…ç†å¤„ç†æ ‡è®°ï¼ˆåœ¨å¼‚å¸¸æƒ…å†µä¸‹ä½¿ç”¨ï¼‰"""
        try:
            self.supabase.table('illustrations_optimized') \
                .update({'processing_session': None}) \
                .eq('processing_session', self.session_id) \
                .execute()
            logger.info("å·²æ¸…ç†å¤„ç†æ ‡è®°")
        except Exception as e:
            logger.error(f"æ¸…ç†å¤„ç†æ ‡è®°å¤±è´¥: {e}")
    
    def run(self):
        """è¿è¡Œå®‰å…¨å¼ºåˆ¶æ›´æ–°"""
        logger.info("ğŸš€ å¼€å§‹å®‰å…¨å¼ºåˆ¶æ›´æ–°ï¼ˆä½¿ç”¨æ–°æç¤ºè¯é‡æ–°å¤„ç†æ‰€æœ‰è®°å½•ï¼‰")
        
        total_records = self.mark_processing_start()
        if total_records == 0:
            logger.info("æ²¡æœ‰éœ€è¦å¤„ç†çš„è®°å½•")
            return
        
        total_processed = 0
        total_success = 0
        start_time = time.time()
        
        try:
            while True:
                # è·å–ä¸‹ä¸€æ‰¹è®°å½•
                records = self.get_next_batch()
                
                if not records:
                    logger.info("âœ… æ‰€æœ‰è®°å½•å¤„ç†å®Œæˆï¼")
                    break
                
                logger.info(f"å¼€å§‹å¤„ç†æ‰¹æ¬¡ï¼š{len(records)} æ¡è®°å½•")
                
                # å¤„ç†å½“å‰æ‰¹æ¬¡
                batch_success = 0
                for record in records:
                    try:
                        if self.process_single_record(record):
                            batch_success += 1
                            total_success += 1
                        
                        total_processed += 1
                        
                        # è¿›åº¦æ˜¾ç¤º
                        progress = (total_processed / total_records * 100) if total_records > 0 else 0
                        elapsed = time.time() - start_time
                        if total_processed > 0:
                            avg_time = elapsed / total_processed
                            remaining_time = (total_records - total_processed) * avg_time / 60
                            logger.info(f"ğŸ“Š è¿›åº¦: {total_processed}/{total_records} ({progress:.1f}%) "
                                      f"æˆåŠŸ: {total_success} é¢„è®¡å‰©ä½™: {remaining_time:.1f}åˆ†é’Ÿ")
                        
                        # æ·»åŠ å»¶è¿Ÿ
                        time.sleep(0.2)
                        
                    except Exception as e:
                        logger.error(f"å¤„ç†è®°å½•æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                        continue
                
                logger.info(f"æ‰¹æ¬¡å®Œæˆ: {batch_success}/{len(records)} æˆåŠŸ")
                time.sleep(1)  # æ‰¹æ¬¡é—´ä¼‘æ¯
                
        except KeyboardInterrupt:
            logger.info("ç”¨æˆ·ä¸­æ–­å¤„ç†")
            self.cleanup_processing_marks()
        except Exception as e:
            logger.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            self.cleanup_processing_marks()
        
        elapsed_time = time.time() - start_time
        logger.info(f"ğŸ‰ å¤„ç†å®Œæˆï¼æ€»è®¡: {total_processed} æ¡ï¼ŒæˆåŠŸ: {total_success} æ¡")
        logger.info(f"â±ï¸  æ€»ç”¨æ—¶: {elapsed_time/60:.1f}åˆ†é’Ÿ")

def main():
    """ä¸»å‡½æ•°"""
    try:
        updater = SafeForceUpdater()
        updater.run()
    except KeyboardInterrupt:
        logger.info("ç”¨æˆ·ä¸­æ–­ç¨‹åº")
    except Exception as e:
        logger.error(f"ç¨‹åºè¿è¡Œå‡ºé”™: {e}")

if __name__ == "__main__":
    main()