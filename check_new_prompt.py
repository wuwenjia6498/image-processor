#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†æ–°çš„è¯¦ç»†æç¤ºè¯ç”Ÿæˆå­—æ®µ
é€šè¿‡åˆ†æå­—æ®µå†…å®¹çš„ç‰¹å¾æ¥åˆ¤æ–­æ˜¯å¦ç¬¦åˆæ–°æç¤ºè¯çš„è¦æ±‚
"""

import re
from datetime import datetime, timedelta

def analyze_prompt_version(record: dict) -> dict:
    """åˆ†æè®°å½•æ˜¯å¦ä½¿ç”¨äº†æ–°æç¤ºè¯"""
    
    # æ–°æç¤ºè¯çš„ç‰¹å¾å…³é”®è¯ï¼ˆæ›´å®½æ¾çš„åŒ¹é…ï¼‰
    new_prompt_indicators = {
        'theme_philosophy': [
            'ä»·å€¼è§‚', 'äººç”Ÿæ€åº¦', 'ä¸–ç•Œè§‚', 'å“²ç†', 'äººç”Ÿä¸»é¢˜', 'å¯¹ç¾çš„çœ‹æ³•', 
            'ç”Ÿæ´»çš„æ„ä¹‰', 'å¹¸ç¦çš„å®šä¹‰', 'é™æ€ä»·å€¼è§‚', 'äººç”Ÿè§‚', 'æˆé•¿', 'æ€è€ƒ',
            'é‡è¦æ€§', 'åŠ›é‡', 'æ¸´æœ›', 'çŸ›ç›¾', 'æ”¯æŒ', 'æƒè¡¡', 'æ¥çº³', 'æ¢ç´¢'
        ],
        'action_process': [
            'åŠ¨æ€è¡Œä¸º', 'ç»å†ä»€ä¹ˆæŒ‘æˆ˜', 'å¦‚ä½•å…‹æœ', 'æˆé•¿è¿‡ç¨‹', 'æ¢ç´¢è¿‡ç¨‹',
            'åšæŒä¸æ‡ˆ', 'çŠ¯é”™å­¦ä¹ ', 'åŠªåŠ›å¥‹æ–—', 'è¡Œä¸ºè¡¨ç°', 'æŒ‘æˆ˜åº”å¯¹',
            'å±•ç°', 'è¡¨è¾¾', 'å˜åŒ–', 'å½’å®¶', 'æœŸå¾…', 'è¿‡ç¨‹', 'åŠ¨ä½œ', 'æ‰‹åŠ¿'
        ],
        'interpersonal_roles': [
            'äººé™…å…³ç³»', 'æƒ…æ„Ÿè¿æ¥', 'äº²å­å…³ç³»', 'å¸ˆç”Ÿå…³ç³»', 'æœ‹å‹å…³ç³»',
            'å…³çˆ±äº’åŠ¨', 'æ”¯æŒé™ªä¼´', 'å¼•å¯¼æ•™è‚²', 'æƒ…æ„Ÿäº¤æµ', 'è§’è‰²äº’åŠ¨',
            'äº²å­', 'å…³ç³»', 'è¿æ¥', 'äº’åŠ¨', 'è§’è‰²', 'å…³æ€€', 'ä¿æŠ¤', 'æ²Ÿé€š'
        ],
        'edu_value': [
            'æ•™è‚²æ„ä¹‰', 'å“æ ¼å¡‘é€ ', 'æ‹“å®½è§†é‡', 'åŸ¹å…»å®¡ç¾', 'å®è§‚æ•™è‚²',
            'å“æ ¼åŸ¹å…»', 'è§†é‡å¼€é˜”', 'å®¡ç¾æ•™è‚²', 'æ•™è‚²ä»·å€¼', 'æˆé•¿å¯å‘',
            'åŸ¹å…»', 'ç†è§£', 'å¸®åŠ©', 'æ„è¯†', 'åŒæƒ…å¿ƒ', 'è´£ä»»æ„Ÿ', 'ä»·å€¼'
        ],
        'learning_strategy': [
            'å­¦ä¹ æ–¹æ³•', 'è§‚å¯Ÿèƒ½åŠ›', 'æé—®æŠ€å·§', 'å¯¹æ¯”åˆ†æ', 'è¾“å‡ºè¡¨è¾¾',
            'è§’è‰²æ‰®æ¼”', 'å­¦ä¹ ç­–ç•¥', 'è®¤çŸ¥æ–¹æ³•', 'æ€ç»´è®­ç»ƒ', 'å­¦ä¹ æŠ€èƒ½',
            'è§‚å¯Ÿ', 'å­¦ä¹ ', 'ç†è§£', 'è¡¨è¾¾', 'æ²Ÿé€š', 'åˆ†æ', 'æ€è€ƒ'
        ],
        'creative_play': [
            'åˆ›æ„æ¸¸æˆ', 'æƒ³è±¡åŠ›', 'åˆ›é€ åŠ›', 'å¹»æƒ³ä¸–ç•Œ', 'è§’è‰²æ‰®æ¼”æ¸¸æˆ',
            'åˆ›æ„è¡¨è¾¾', 'æƒ³è±¡ç©ºé—´', 'åˆ›é€ æ€§æ€ç»´', 'æ¸¸æˆåŒ–å­¦ä¹ ', 'åˆ›æ„å¯å‘',
            'æƒ³è±¡', 'æ¿€å‘', 'åˆ›é€ ', 'é¼“åŠ±', 'æ‰®æ¼”', 'æ¢ç´¢'
        ],
        'scene_visuals': [
            'åœºæ™¯æè¿°', 'å®¤å†…å¤–ç¯å¢ƒ', 'å­£èŠ‚ç‰¹å¾', 'å¤©æ°”çŠ¶å†µ', 'å…‰çº¿æ•ˆæœ',
            'è‰²å½©è¿ç”¨', 'è‰ºæœ¯é£æ ¼', 'æ•´ä½“æ°›å›´', 'è§†è§‰å…ƒç´ ', 'ç¯å¢ƒè¥é€ ',
            'åœºæ™¯', 'æ°›å›´', 'è‰²å½©', 'è§†è§‰', 'ç”»é¢', 'èƒŒæ™¯', 'é£æ ¼', 'æ„å›¾'
        ]
    }
    
    # æ—§æç¤ºè¯çš„ç‰¹å¾ï¼ˆç®€å•ã€æ¨¡ç³Šçš„æè¿°ï¼‰
    old_prompt_indicators = [
        'ä»æ–‡æœ¬ä¸­æç‚¼å‡º', 'æ ¹æ®ä¸Šè¿°æŒ‡å—åˆ†æå¾—å‡º', 'åœ¨æ­¤å¡«å†™',
        'æè¿°äº†', 'å±•ç°äº†', 'ä½“ç°äº†', 'è¡¨è¾¾äº†', 'åæ˜ äº†',
        'ç®€å•çš„', 'åŸºæœ¬çš„', 'ä¸€èˆ¬çš„', 'æ™®é€šçš„'
    ]
    
    analysis = {
        'is_new_prompt': True,
        'confidence': 0,
        'field_scores': {},
        'issues': [],
        'evidence': []
    }
    
    total_score = 0
    field_count = 0
    
    for field, keywords in new_prompt_indicators.items():
        content = record.get(field, '').strip()
        
        if not content:
            analysis['issues'].append(f"{field}å­—æ®µä¸ºç©º")
            continue
            
        field_count += 1
        field_score = 0
        
        # æ£€æŸ¥æ–°æç¤ºè¯å…³é”®è¯
        matched_keywords = []
        for keyword in keywords:
            if keyword in content:
                field_score += 1
                matched_keywords.append(keyword)
        
        # æ£€æŸ¥æ—§æç¤ºè¯ç‰¹å¾
        old_indicators_found = []
        for indicator in old_prompt_indicators:
            if indicator in content:
                field_score -= 2  # æ‰£åˆ†
                old_indicators_found.append(indicator)
        
        # é•¿åº¦å’Œå¤æ‚æ€§æ£€æŸ¥
        if len(content) < 20:
            field_score -= 1
            analysis['issues'].append(f"{field}å†…å®¹è¿‡çŸ­")
        elif len(content) > 150:
            field_score += 1  # è¯¦ç»†å†…å®¹åŠ åˆ†
        
        # å…·ä½“æ€§æ£€æŸ¥
        if any(word in content for word in ['å…·ä½“', 'è¯¦ç»†', 'æ·±å…¥', 'ä¸°å¯Œ', 'å…¨é¢']):
            field_score += 1
        
        # æŠ½è±¡æ€§æ£€æŸ¥ï¼ˆæ—§æç¤ºè¯ç‰¹å¾ï¼‰
        if any(word in content for word in ['æŠ½è±¡', 'æ¨¡ç³Š', 'å¤§æ¦‚', 'å¯èƒ½', 'ä¼¼ä¹']):
            field_score -= 1
        
        analysis['field_scores'][field] = {
            'score': field_score,
            'matched_keywords': matched_keywords,
            'old_indicators': old_indicators_found,
            'length': len(content)
        }
        
        total_score += field_score
        
        # è®°å½•è¯æ®
        if matched_keywords:
            analysis['evidence'].append(f"{field}: åŒ¹é…å…³é”®è¯ {matched_keywords}")
        if old_indicators_found:
            analysis['evidence'].append(f"{field}: å‘ç°æ—§æ ¼å¼ç‰¹å¾ {old_indicators_found}")
    
    # è®¡ç®—æ€»ä½“ç½®ä¿¡åº¦
    if field_count > 0:
        avg_score = total_score / field_count
        analysis['confidence'] = max(0, min(100, (avg_score + 2) * 25))  # è½¬æ¢ä¸º0-100çš„ç½®ä¿¡åº¦
        analysis['is_new_prompt'] = avg_score > 0
    
    return analysis

def check_prompt_usage():
    """æ£€æŸ¥æ•°æ®åº“ä¸­è®°å½•ä½¿ç”¨çš„æç¤ºè¯ç‰ˆæœ¬"""
    try:
        import config
        from supabase import create_client
        
        supabase = create_client(config.SUPABASE_URL, config.SUPABASE_ANON_KEY)
        
        # è·å–æ‰€æœ‰å·²å¤„ç†çš„è®°å½•
        response = supabase.table('illustrations_optimized') \
            .select('id, filename, theme_philosophy, action_process, interpersonal_roles, edu_value, learning_strategy, creative_play, scene_visuals, updated_at') \
            .not_.is_('theme_philosophy', 'null') \
            .order('updated_at', desc=True) \
            .execute()
        
        records = response.data
        
        if not records:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°å·²å¤„ç†çš„è®°å½•")
            return
        
        print(f"ğŸ” åˆ†æ {len(records)} æ¡è®°å½•çš„æç¤ºè¯ç‰ˆæœ¬...")
        print("=" * 80)
        
        # ç»Ÿè®¡æ•°æ®
        new_prompt_count = 0
        old_prompt_count = 0
        uncertain_count = 0
        
        # æŒ‰æ—¶é—´åˆ†ç»„
        today = datetime.now().date()
        recent_records = []
        old_records = []
        
        detailed_results = []
        
        for i, record in enumerate(records):
            analysis = analyze_prompt_version(record)
            
            # æ—¶é—´åˆ†æ
            is_recent = False
            if record.get('updated_at'):
                try:
                    update_time = datetime.fromisoformat(record['updated_at'].replace('Z', '+00:00')).date()
                    is_recent = update_time >= today
                    if is_recent:
                        recent_records.append((record, analysis))
                    else:
                        old_records.append((record, analysis))
                except:
                    pass
            
            # åˆ†ç±»ç»Ÿè®¡
            if analysis['confidence'] >= 70:
                if analysis['is_new_prompt']:
                    new_prompt_count += 1
                    status = "ğŸ†• æ–°æç¤ºè¯"
                else:
                    old_prompt_count += 1
                    status = "ğŸ“œ æ—§æç¤ºè¯"
            else:
                uncertain_count += 1
                status = "â“ ä¸ç¡®å®š"
            
            detailed_results.append({
                'record': record,
                'analysis': analysis,
                'status': status,
                'is_recent': is_recent
            })
            
            # æ˜¾ç¤ºå‰15æ¡è¯¦ç»†ç»“æœ
            if i < 15:
                print(f"\nğŸ“ è®°å½• {i+1}: {record['id']}")
                print(f"   æ–‡ä»¶: {record.get('filename', 'N/A')}")
                print(f"   æ—¶é—´: {record.get('updated_at', 'N/A')}")
                print(f"   çŠ¶æ€: {status} (ç½®ä¿¡åº¦: {analysis['confidence']:.1f}%)")
                
                if analysis['confidence'] < 50:
                    print(f"   âš ï¸  é—®é¢˜: {', '.join(analysis['issues'][:3])}")
                
                # æ˜¾ç¤ºå­—æ®µå¾—åˆ†
                high_score_fields = [k for k, v in analysis['field_scores'].items() if v['score'] >= 2]
                low_score_fields = [k for k, v in analysis['field_scores'].items() if v['score'] < 0]
                
                if high_score_fields:
                    print(f"   âœ… é«˜è´¨é‡å­—æ®µ: {', '.join(high_score_fields)}")
                if low_score_fields:
                    print(f"   âŒ ä½è´¨é‡å­—æ®µ: {', '.join(low_score_fields)}")
        
        if len(records) > 15:
            print(f"\n... (æ˜¾ç¤ºå‰15æ¡è¯¦ç»†ä¿¡æ¯ï¼Œå…±{len(records)}æ¡)")
        
        # æ€»ç»“æŠ¥å‘Š
        print("\n" + "=" * 80)
        print("ğŸ“Š æç¤ºè¯ç‰ˆæœ¬åˆ†ææŠ¥å‘Š")
        print("=" * 80)
        
        total = len(records)
        print(f"ğŸ“ˆ æ€»ä½“ç»Ÿè®¡:")
        print(f"   æ€»è®°å½•æ•°: {total}")
        print(f"   ğŸ†• æ–°æç¤ºè¯: {new_prompt_count} ({new_prompt_count/total*100:.1f}%)")
        print(f"   ğŸ“œ æ—§æç¤ºè¯: {old_prompt_count} ({old_prompt_count/total*100:.1f}%)")
        print(f"   â“ ä¸ç¡®å®š: {uncertain_count} ({uncertain_count/total*100:.1f}%)")
        
        print(f"\nâ° æ—¶é—´åˆ†æ:")
        print(f"   ä»Šæ—¥æ›´æ–°: {len(recent_records)} æ¡")
        print(f"   å†å²è®°å½•: {len(old_records)} æ¡")
        
        if recent_records:
            recent_new = sum(1 for _, analysis in recent_records if analysis['is_new_prompt'] and analysis['confidence'] >= 70)
            print(f"   ä»Šæ—¥æ–°æç¤ºè¯æ¯”ä¾‹: {recent_new}/{len(recent_records)} ({recent_new/len(recent_records)*100:.1f}%)")
        
        # å»ºè®®
        print(f"\nğŸ’¡ å»ºè®®:")
        if old_prompt_count > total * 0.3:
            print(f"   â— å‘ç° {old_prompt_count} æ¡ä½¿ç”¨æ—§æç¤ºè¯çš„è®°å½•")
            print(f"   ğŸ”„ å¼ºçƒˆå»ºè®®è¿è¡Œ: python process_illustrations_data.py --force-update")
        elif uncertain_count > total * 0.2:
            print(f"   âš ï¸  å‘ç° {uncertain_count} æ¡è´¨é‡ä¸ç¡®å®šçš„è®°å½•")
            print(f"   ğŸ” å»ºè®®æ£€æŸ¥APIé…ç½®æˆ–é‡æ–°å¤„ç†éƒ¨åˆ†è®°å½•")
        elif new_prompt_count > total * 0.8:
            print(f"   âœ… å¤§éƒ¨åˆ†è®°å½•({new_prompt_count}/{total})å·²ä½¿ç”¨æ–°æç¤ºè¯ï¼Œè´¨é‡è‰¯å¥½")
        else:
            print(f"   ğŸ”„ å»ºè®®è¿è¡Œå¼ºåˆ¶æ›´æ–°ä»¥ç¡®ä¿æ‰€æœ‰è®°å½•ä½¿ç”¨æ–°æç¤ºè¯")
        
        # æ˜¾ç¤ºéœ€è¦é‡æ–°å¤„ç†çš„è®°å½•ID
        need_update = [r['record']['id'] for r in detailed_results 
                      if not r['analysis']['is_new_prompt'] or r['analysis']['confidence'] < 70]
        
        if need_update and len(need_update) <= 20:
            print(f"\nğŸ“‹ éœ€è¦é‡æ–°å¤„ç†çš„è®°å½•ID:")
            for record_id in need_update[:10]:
                print(f"   {record_id}")
            if len(need_update) > 10:
                print(f"   ... è¿˜æœ‰{len(need_update)-10}æ¡")
        
    except Exception as e:
        print(f"âŒ æ£€æŸ¥å¤±è´¥: {e}")

if __name__ == "__main__":
    print("ğŸ” æ–°æç¤ºè¯ä½¿ç”¨æƒ…å†µæ£€æŸ¥")
    print("=" * 50)
    
    check_prompt_usage()
    
    print(f"\nğŸ¯ å¦‚æœå‘ç°å¤§é‡æ—§æç¤ºè¯è®°å½•:")
    print(f"   è¿è¡Œ: python process_illustrations_data.py --force-update")
    print(f"   è¿™å°†ä½¿ç”¨æ–°çš„è¯¦ç»†æç¤ºè¯é‡æ–°å¤„ç†æ‰€æœ‰è®°å½•")